# **ğŸš— Predicting Car Prices with Random Forest Regressor ğŸš—**

## **ğŸ“‹ Table of Contents**
1. [Introduction](#introduction)
2. [Project Overview](#project-overview)
3. [Data Preparation](#data-preparation)
4. [Feature Engineering](#feature-engineering)
5. [Model Building](#model-building)
6. [Model Evaluation](#model-evaluation)
7. [Additional Models Tested](#additional-models-tested)
8. [Model Saving & Deployment](#model-saving--deployment)
9. [Results and Conclusions](#results-and-conclusions)
10. [Next Steps](#next-steps)
11. [Getting Started](#getting-started)
12. [References](#references)

---

## **1. Introduction ğŸš€**
This project aims to predict car prices using machine learning techniques, focusing primarily on the Random Forest Regressor model. We also explore Multiple Linear Regression and Linear Regression models for comparison. Feature engineering was employed to create new variables that could enhance model performance and provide more accurate predictions.

## **2. Project Overview ğŸ”**
The project consists of the following key sections:
- **ğŸ§¹ Data Preparation:** Cleaning and preprocessing the dataset.
- **ğŸ”§ Feature Engineering:** Creating new features to improve model accuracy.
- **ğŸ¤– Model Building:** Constructing and tuning the Random Forest Regressor, with comparison to other models.
- **ğŸ“Š Model Evaluation:** Assessing model performance using metrics such as RÂ² Score, RMSE, and Cross-Validation.
- **ğŸ’¾ Model Saving & Deployment:** Saving and deploying the trained model for future use.

## **3. Data Preparation ğŸ› ï¸**
The dataset used includes various features that impact car pricing. The key steps taken during data preparation include:

- **ğŸ“ Columns:**
  - `car_brand`
  - `car_model`
  - `car_variant`
  - `car_year`
  - `car_engine`
  - `car_transmission`
  - `milage`
  - `accident`
  - `flood`
  - `color`
  - `purchase_date`
  - `sales_date`
  - `days_on_market` (Engineered feature)
  - `car_age_at_sale` (Engineered feature)
  - `price` (Target variable)

- **Key Steps:**
  - Handling missing values and outliers.
  - Encoding categorical variables.
  - Splitting the data into training and testing sets.

## **4. Feature Engineering ğŸ› ï¸**
To boost the model's predictive capability, two new features were engineered:

- **`days_on_market`:** Represents the number of days a car was listed for sale.
- **`car_age_at_sale`:** Represents the car's age at the time of sale.

These features are designed to capture additional dimensions that might affect the car's selling price.

## **5. Model Building ğŸ§ **
### **Random Forest Regressor ğŸŒ³**
The Random Forest Regressor is the primary model used, integrated into a pipeline for streamlined processing.

```python
from sklearn.ensemble import RandomForestRegressor
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder

# Define the transformer for feature processing
transformer = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), numerical_features),
        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)
    ],
    remainder='drop'
)

# Initialize and build the pipeline
rf_model = Pipeline([
    ('ColumnTransformer', transformer),
    ('Model', RandomForestRegressor())
])
```

## **6. Model Evaluation ğŸ“**
Models were evaluated using the following metrics:

- **RÂ² Score:** Indicates how well the model explains the variance in the target variable.
- **RMSE (Root Mean Squared Error):** Measures the average magnitude of prediction errors.
- **Cross-Validation:** Assesses model performance on unseen data.

**Final Evaluation Metrics for Random Forest Regressor:**
- **Test RÂ²:** 0.8551
- **Test RMSE:** 11,448.49
- **Cross-Validated RMSE:** 12,661.31
- **Cross-Validated RÂ²:** 0.8081

## **7. Additional Models Tested ğŸ§ª**
For comparative analysis, the following models were also tested:

- **Multiple Linear Regression:** Used to understand linear relationships between features and the target variable.
- **Linear Regression:** Served as a baseline model for comparison with more complex models.

```python
from sklearn.linear_model import LinearRegression

# Define the pipeline for Multiple Linear Regression
mlr_model = Pipeline([
    ('ColumnTransformer', transformer),
    ('Model', LinearRegression())
])
```

## **8. Model Saving & Deployment ğŸ’¾**
The trained Random Forest Regressor model is saved using Python's `pickle` module, allowing for easy future use and deployment.

```python
import pickle

# Save the pipeline and model
with open('rf_model_pipeline.pkl', 'wb') as file:
    pickle.dump(rf_model, file)

# Load the saved model
with open('rf_model_pipeline.pkl', 'rb') as file:
    loaded_pipeline = pickle.load(file)
```

## **9. Results and Conclusions ğŸ**
The Random Forest Regressor demonstrated strong performance, making it an effective tool for predicting car prices. The comparative analysis with multiple linear regression and linear regression models provided valuable insights into the relative performance of different approaches.

## **10. Next Steps â­ï¸**
- **Deployment:** Explore deployment options using platforms such as AWS or Azure.
- **Model Interpretability:** Implement methods like SHAP or LIME to understand feature importance and make the model more interpretable.

## **11. Getting Started ğŸ› ï¸**
To run this project locally:
1. **Clone this repository.**
2. **Install the required dependencies** using `pip install -r requirements.txt`.
3. **Execute the provided Jupyter notebook or Python scripts** to run the analysis.
4. **Use the saved model** for predictions or further analysis.

## **12. References ğŸ“š**
- [Scikit-learn Documentation](https://scikit-learn.org/stable/user_guide.html)
- [Pandas Documentation](https://pandas.pydata.org/pandas-docs/stable/)
- [Matplotlib Documentation](https://matplotlib.org/stable/contents.html)
- [SHAP Documentation](https://shap.readthedocs.io/en/latest/)
- [LIME Documentation](https://github.com/marcotcr/lime)

---
